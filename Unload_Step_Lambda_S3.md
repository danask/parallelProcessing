
ì¢‹ìŠµë‹ˆë‹¤. ì•„ë˜ëŠ” ë‹¹ì‹ ì˜ ëª©í‘œë¥¼ ì™„ì „í•˜ê²Œ ì§€ì›í•˜ëŠ” **Spring Boot + Step Functions + Lambda + Kafka + Terraform ì¸í”„ë¼ êµ¬ì„±**ì˜ ì „ì²´ íë¦„ ë° êµ¬í˜„ ì˜ˆì‹œì…ë‹ˆë‹¤.

---

# âœ… ëª©í‘œ ì •ë¦¬

1. **Spring Boot**ë¡œ ì‚¬ìš©ì ìš”ì²­ ìˆ˜ì‹  ë° **Step Function ì‹œì‘**
2. Step Function:

   * Redshift UNLOAD ì‹¤í–‰ (Lambda1)
   * S3 í™•ì¸ (Lambda2)
   * Kafkaë¡œ ì•Œë¦¼ ì „ì†¡ (Lambda3)
3. Kafka ì´ë²¤íŠ¸ë¥¼ **Spring Bootì—ì„œ ìˆ˜ì‹  ë° ì²˜ë¦¬**
4. **Terraformìœ¼ë¡œ ëª¨ë“  AWS ìì› ë°°í¬**

---

## ğŸ§± 1. Maven ì„¤ì •

### `pom.xml` ì£¼ìš” ì˜ì¡´ì„±:

```xml
<dependencies>
  <!-- AWS SDK -->
  <dependency>
    <groupId>com.amazonaws</groupId>
    <artifactId>aws-java-sdk-stepfunctions</artifactId>
    <version>1.12.686</version>
  </dependency>

  <!-- Kafka -->
  <dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
  </dependency>

  <!-- JSON -->
  <dependency>
    <groupId>com.fasterxml.jackson.core</groupId>
    <artifactId>jackson-databind</artifactId>
  </dependency>
</dependencies>
```

---

## ğŸ” 2. Kafka ìˆ˜ì‹  â€“ Spring Boot Consumer

### Kafka ì„¤ì • (`application.yml`):

```yaml
spring:
  kafka:
    bootstrap-servers: localhost:9092
    consumer:
      group-id: unload-notifier
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
```

### Kafka Consumer í´ë˜ìŠ¤:

```java
@Slf4j
@Component
public class UnloadKafkaListener {

    private final UnloadResultRepository repository;

    public UnloadKafkaListener(UnloadResultRepository repository) {
        this.repository = repository;
    }

    @KafkaListener(topics = "unload-complete", groupId = "unload-notifier")
    public void handleUnloadResult(String message) {
        try {
            ObjectMapper mapper = new ObjectMapper();
            JsonNode json = mapper.readTree(message);
            String requestId = json.get("requestId").asText();
            String s3Url = json.get("s3FileUrl").asText();

            UnloadResult result = repository.findById(requestId).orElseThrow();
            result.setStatus(UnloadResult.Status.DONE);
            result.setS3FileUrl(s3Url);
            repository.save(result);

            log.info("Updated result for requestId {} with link {}", requestId, s3Url);
        } catch (Exception e) {
            log.error("Failed to process Kafka message: {}", message, e);
        }
    }
}
```

---

## ğŸ—ï¸ 3. Terraform êµ¬ì„±

Terraformìœ¼ë¡œ ë‹¤ìŒ ìì›ì„ ìƒì„±í•©ë‹ˆë‹¤:

* Step Function
* 3ê°œì˜ Lambda
* IAM Roles
* S3 Bucket (optional)
* Kafka ì„¤ì •ì€ MSK ë˜ëŠ” ë³„ë„ êµ¬ì„± ê°€ì •

---

### `main.tf` ì˜ˆì‹œ (í•µì‹¬)

```hcl
provider "aws" {
  region = "us-east-1"
}

resource "aws_iam_role" "lambda_exec_role" {
  name = "lambda_exec_role"
  assume_role_policy = jsonencode({
    Version = "2012-10-17",
    Statement = [{
      Action    = "sts:AssumeRole"
      Principal = { Service = "lambda.amazonaws.com" }
      Effect    = "Allow"
    }]
  })
}

resource "aws_lambda_function" "unload_lambda" {
  filename         = "unloadHandler.zip"
  function_name    = "StartUnloadFunction"
  handler          = "unloadHandler.lambda_handler"
  runtime          = "python3.9"
  role             = aws_iam_role.lambda_exec_role.arn
  source_code_hash = filebase64sha256("unloadHandler.zip")
}

resource "aws_lambda_function" "check_lambda" {
  filename         = "checkS3Handler.zip"
  function_name    = "CheckS3FileFunction"
  handler          = "checkS3Handler.lambda_handler"
  runtime          = "python3.9"
  role             = aws_iam_role.lambda_exec_role.arn
  source_code_hash = filebase64sha256("checkS3Handler.zip")
}

resource "aws_lambda_function" "kafka_lambda" {
  filename         = "sendKafkaHandler.zip"
  function_name    = "SendKafkaFunction"
  handler          = "sendKafkaHandler.lambda_handler"
  runtime          = "python3.9"
  role             = aws_iam_role.lambda_exec_role.arn
  source_code_hash = filebase64sha256("sendKafkaHandler.zip")
}

resource "aws_sfn_state_machine" "unload_state_machine" {
  name     = "RedshiftUnloadStateMachine"
  role_arn = aws_iam_role.lambda_exec_role.arn

  definition = file("unloadWorkflow.asl.json")
}
```

---

### Step Function ì •ì˜ íŒŒì¼ â€“ `unloadWorkflow.asl.json`

ì´ íŒŒì¼ì€ ìœ„ì—ì„œ ë§Œë“  `.asl.json` ë‚´ìš© ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.

```bash
terraform apply
```

> ğŸ’¡ Lambda zip íŒŒì¼ì€ `unloadHandler.zip` ë“±ìœ¼ë¡œ ë¯¸ë¦¬ ë¹Œë“œí•˜ê³  S3ë¡œ ë°°í¬í•˜ê±°ë‚˜ `file()` ë¡œ ë¡œì»¬ ì°¸ì¡° ê°€ëŠ¥

---

## ğŸ¯ ì „ì²´ íë¦„ ìš”ì•½

```
[Spring Boot API í˜¸ì¶œ]
     â†“
StepFunction ì‹¤í–‰ (StartExecution)
     â†“
Lambda #1: Redshift UNLOAD ìˆ˜í–‰
     â†“
Lambda #2: S3 íŒŒì¼ ì¡´ì¬ í™•ì¸ (Wait ë°˜ë³µ)
     â†“
Lambda #3: Kafka ì´ë²¤íŠ¸ ë°œí–‰
     â†“
Spring Kafka Listener ìˆ˜ì‹  â†’ DB ì—…ë°ì´íŠ¸
```

---

## âœ… ê·¸ ì™¸ í™•ì¥ í¬ì¸íŠ¸

| ê¸°ëŠ¥                | ì„¤ëª…                                               |
| ----------------- | ------------------------------------------------ |
| Pre-signed URL ë°œê¸‰ | ì‚¬ìš©ìê°€ ë‹¤ìš´ë¡œë“œ ì‹œ `s3Client.generatePresignedUrl()` ì‚¬ìš© |
| ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„          | Step Functionì˜ `Retry` ì†ì„± ì‚¬ìš© ê°€ëŠ¥                  |
| ì´ë©”ì¼ ì•Œë¦¼ ì—°ë™         | Lambdaì—ì„œ SESë‚˜ Slack Webhook í˜¸ì¶œ ê°€ëŠ¥                |

---

## âœ‹ ë‹¤ìŒ ë‹¨ê³„ë¡œ ë„ì™€ë“œë¦´ ìˆ˜ ìˆëŠ” ê²ƒ

* Lambda ì½”ë“œë¥¼ SAM ë˜ëŠ” CDKë¡œ ë°°í¬
* Kafkaë¥¼ MSK (Amazon Managed Streaming for Kafka)ë¡œ ì—°ë™
* `CloudWatch Logs`, `DLQ`, `S3 Versioning` ë“± ìš´ì˜ ì•ˆì •í™”
* Terraformì— output/export ì¶”ê°€

í•„ìš”í•œ ì„¸ë¶€ ì˜ì—­ì„ ì§€ì •í•´ ì£¼ì‹œë©´ í•´ë‹¹ ë¶€ë¶„ë¶€í„° í™•ì¥í•´ë“œë¦´ê²Œìš”!

----

ì¢‹ìŠµë‹ˆë‹¤! ì•„ë˜ëŠ” **Spring Boot ê¸°ë°˜ì—ì„œ Redshift UNLOAD â†’ S3 â†’ Kafka ì•Œë¦¼ê¹Œì§€ ì „ì²´ íë¦„ì„ Step Functionsë¡œ êµ¬ì„±í•˜ê³  ì‹¤í–‰í•˜ëŠ” êµ¬ì¡°**ì…ë‹ˆë‹¤.

---

## âœ… êµ¬ì„± ìš”ì†Œ ìš”ì•½

| êµ¬ì„± ìš”ì†Œ              | ì„¤ëª…                                   |
| ------------------ | ------------------------------------ |
| Spring Boot API    | Step Function ì‹¤í–‰ ìš”ì²­                  |
| AWS Step Functions | ì „ì²´ íë¦„ ì œì–´ (UNLOAD â†’ ìƒíƒœ í™•ì¸ â†’ Kafka ë°œí–‰) |
| Lambda #1          | Redshiftì— UNLOAD ì‹¤í–‰                  |
| Lambda #2          | S3ì—ì„œ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸                     |
| Lambda #3          | Kafka ì´ë²¤íŠ¸ ë°œí–‰                         |
| S3                 | UNLOAD ê²°ê³¼ ì €ì¥                         |
| Kafka              | ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼ ì „íŒŒ                          |

---

## âœ… ìµœì¢… ì•„ì›ƒí’‹

ì•„ë˜ íŒŒì¼ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤:

1. \[`unloadWorkflow.asl.json`] â€“ Step Function ì •ì˜
2. \[`lambda/unloadHandler.py`] â€“ Redshift UNLOAD ì‹¤í–‰ Lambda
3. \[`lambda/checkS3Handler.py`] â€“ S3 ê²°ê³¼ íŒŒì¼ í™•ì¸ Lambda
4. \[`lambda/sendKafkaHandler.py`] â€“ Kafkaë¡œ ê²°ê³¼ ë°œì†¡ Lambda
5. \[`application.yml`] â€“ Spring ì„¤ì •
6. \[`UnloadStepFunctionService.java`] â€“ Spring Bootì—ì„œ Step Function ì‹œì‘ ì½”ë“œ

---

## ğŸ“„ `unloadWorkflow.asl.json` (Step Function ì •ì˜)

```json
{
  "Comment": "UNLOAD from Redshift and notify via Kafka",
  "StartAt": "StartUnload",
  "States": {
    "StartUnload": {
      "Type": "Task",
      "Resource": "arn:aws:lambda:REGION:ACCOUNT_ID:function:StartUnloadFunction",
      "Next": "WaitForFile"
    },
    "WaitForFile": {
      "Type": "Wait",
      "Seconds": 30,
      "Next": "CheckFileExists"
    },
    "CheckFileExists": {
      "Type": "Task",
      "Resource": "arn:aws:lambda:REGION:ACCOUNT_ID:function:CheckS3FileFunction",
      "Next": "FileExists?"
    },
    "FileExists?": {
      "Type": "Choice",
      "Choices": [
        {
          "Variable": "$.fileExists",
          "BooleanEquals": true,
          "Next": "SendKafkaEvent"
        }
      ],
      "Default": "WaitForFile"
    },
    "SendKafkaEvent": {
      "Type": "Task",
      "Resource": "arn:aws:lambda:REGION:ACCOUNT_ID:function:SendKafkaFunction",
      "End": true
    }
  }
}
```

---

## ğŸ `lambda/unloadHandler.py` (Lambda #1 - UNLOAD)

```python
import psycopg2

def lambda_handler(event, context):
    request_id = event['requestId']
    sql = event['sql']
    s3_path = f"s3://your-bucket/unload-results/{request_id}/output"
    creds = "aws_access_key_id=XXX;aws_secret_access_key=YYY"

    unload_sql = f"""
        UNLOAD ('{sql}')
        TO '{s3_path}'
        CREDENTIALS '{creds}'
        DELIMITER ',' ADDQUOTES GZIP ALLOWOVERWRITE PARALLEL OFF;
    """

    conn = psycopg2.connect(...)
    with conn.cursor() as cur:
        cur.execute(unload_sql)
    conn.close()
    
    return { "requestId": request_id, "s3Path": s3_path }
```

---

## ğŸ `lambda/checkS3Handler.py` (Lambda #2 - S3 í™•ì¸)

```python
import boto3

def lambda_handler(event, context):
    s3 = boto3.client('s3')
    request_id = event['requestId']
    bucket = "your-bucket"
    key = f"unload-results/{request_id}/output000.gz"

    exists = False
    try:
        s3.head_object(Bucket=bucket, Key=key)
        exists = True
    except:
        exists = False

    event['fileExists'] = exists
    return event
```

---

## ğŸ `lambda/sendKafkaHandler.py` (Lambda #3 - Kafka ì•Œë¦¼)

```python
from kafka import KafkaProducer
import json

def lambda_handler(event, context):
    producer = KafkaProducer(bootstrap_servers='kafka:9092')
    producer.send("unload-complete", json.dumps({
        "requestId": event['requestId'],
        "s3FileUrl": f"https://{event['s3Path'].replace('s3://', '').replace('/', '.s3.amazonaws.com/', 1)}.gz"
    }).encode('utf-8'))
    return { "status": "sent" }
```

---

## âš™ï¸ `application.yml` (Spring ì„¤ì •)

```yaml
aws:
  stepfunction:
    arn: arn:aws:states:REGION:ACCOUNT_ID:stateMachine:RedshiftUnloadStateMachine
```

---

## â˜• `UnloadStepFunctionService.java` (Springì—ì„œ Step Function ì‹œì‘)

```java
@Service
@RequiredArgsConstructor
public class UnloadStepFunctionService {

    private final AWSStepFunctions stepFunctions;

    @Value("${aws.stepfunction.arn}")
    private String stateMachineArn;

    public void startUnload(String requestId, String sql) {
        Map<String, Object> input = Map.of(
            "requestId", requestId,
            "sql", sql
        );

        StartExecutionRequest request = new StartExecutionRequest()
            .withStateMachineArn(stateMachineArn)
            .withName("unload-" + requestId)
            .withInput(new ObjectMapper().writeValueAsString(input));

        stepFunctions.startExecution(request);
    }
}
```

> `AWSStepFunctions`ëŠ” `com.amazonaws.services.stepfunctions.AWSStepFunctionsClientBuilder.defaultClient()`ë¡œ ìƒì„± ê°€ëŠ¥

---

## âœ… í˜¸ì¶œ ì˜ˆì‹œ

```java
@PostMapping("/api/unload")
public ResponseEntity<?> startUnload(@RequestBody UnloadRequest req) {
    stepFunctionService.startUnload(req.getRequestId(), req.getSql());
    return ResponseEntity.ok("UNLOAD started via StepFunction");
}
```

---

## âœ… ê·¸ ë‹¤ìŒì— í•  ìˆ˜ ìˆëŠ” ê²ƒ

* `KafkaListener`ë¡œ ê²°ê³¼ ìˆ˜ì‹ 
* DBì— ê²°ê³¼ ì €ì¥ (íŒŒì¼ ë§í¬ í¬í•¨)
* ì‚¬ìš©ì polling API ë˜ëŠ” WebSocket ì•Œë¦¼

---

í•„ìš”í•˜ì‹œë©´ ì „ì²´ Maven ì˜ì¡´ì„±, Lambda ë°°í¬ ë°©ë²•, Step Function ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ (`SAM`, `Terraform`, `CDK`) ë„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì§„í–‰í•˜ì‹œë ¤ëŠ” ë°©ì‹ì´ `Lambda + StepFunction ê¸°ë°˜ ìš´ì˜í™˜ê²½`ì´ë©´ ë‹¤ìŒ ë‹¨ê³„ë„ ë„ì™€ë“œë¦´ê²Œìš”!

---

ì¢‹ì€ ì§ˆë¬¸ì…ë‹ˆë‹¤! Redshiftì˜ UNLOAD ì‘ì—…ì€ ë°ì´í„° í¬ê¸°ê°€ í¬ê³ , ì‘ì—… ìì²´ê°€ **ë¹„ë™ê¸°ì²˜ëŸ¼ ëŠë¦´ ìˆ˜ ìˆìœ¼ë©°**, ì‹¤ì œë¡œëŠ” JDBC ì—°ê²°ì—ì„œ **ì¿¼ë¦¬ê°€ ëë‚  ë•Œê¹Œì§€ blocking** ë˜ê¸° ë•Œë¬¸ì— **ëª¨ë‹ˆí„°ë§ê³¼ ì•ˆì •ì„± í™•ë³´**ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤.

### âœ… ìš”ì•½: UNLOAD ì²˜ë¦¬ íë¦„ì˜ ëª¨ë‹ˆí„°ë§ í•„ìš” ì—¬ë¶€

| í•­ëª©                              | í•„ìš” ì—¬ë¶€        | ì´ìœ                                                     |
| ------------------------------- | ------------ | ----------------------------------------------------- |
| **UNLOAD ì‹¤í–‰ ìì²´ì˜ ëª¨ë‹ˆí„°ë§**          | âš ï¸ **ì„ íƒì **   | JDBCë¡œ ì‹¤í–‰í•˜ë©´ blockingì´ì§€ë§Œ, ì‘ì—…ì´ ì˜¤ë˜ ê±¸ë¦¬ê±°ë‚˜ ì‹¤íŒ¨ ì‹œ catchë¡œ ì²˜ë¦¬ ê°€ëŠ¥ |
| **í›„ì† ì²˜ë¦¬ (S3 ì™„ë£Œ â†’ Kafka ì´ë²¤íŠ¸ ë“±)** | âœ… **ê°•ë ¥íˆ ê¶Œì¥** | ì´ë²¤íŠ¸ê°€ ëˆ„ë½ë˜ê±°ë‚˜ ì‹¤íŒ¨í•˜ë©´ ê²°ê³¼ ì „ë‹¬ ì•ˆ ë¨                             |
| **ì „ì²´ workflow ì¶”ì  (end-to-end)** | âœ… **ê¶Œì¥**     | ì‚¬ìš©ìê°€ `requestId`ë¡œ ì§„í–‰ ìƒíƒœë¥¼ ë³¼ ìˆ˜ ìˆì–´ì•¼ í•¨                    |

---

## âœ… ì„ íƒì§€ 1: Step Functions ë„ì… (ê¶Œì¥ ìƒí™©)

Step FunctionsëŠ” ì•„ë˜ì™€ ê°™ì€ ì¡°ê±´ì— ì í•©í•©ë‹ˆë‹¤:

* UNLOAD ì‘ì—…ì´ ê¸¸ê³  ë¶ˆì•ˆì •í•  ìˆ˜ ìˆìŒ
* UNLOAD ì´í›„ Lambda, Kafka, S3 ë“±ì„ ì—®ì€ **ë¹„ë™ê¸° íë¦„**ì´ ì¡´ì¬í•¨
* ì „ì²´ ì›Œí¬í”Œë¡œìš° ì„±ê³µ/ì‹¤íŒ¨ë¥¼ ì¶”ì í•˜ê³  ì‹¶ìŒ

### ì˜ˆì‹œ Step Function Workflow:

```
[Start]
   â†“
[StartUnload Lambda]   â†’ UNLOAD ì‹¤í–‰ (JDBC or boto3)
   â†“
[Wait / Check Status]  â†’ Redshift query ìƒíƒœ or polling
   â†“
[S3 íŒŒì¼ ì¡´ì¬ í™•ì¸]    â†’ S3ì— ê²°ê³¼ íŒŒì¼ ìƒì„±ëëŠ”ì§€ í™•ì¸
   â†“
[SendKafkaEvent Lambda]
   â†“
[Done]
```

ì´ êµ¬ì¡°ëŠ”:

* ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ì„¤ì • ê°€ëŠ¥
* ì‘ì—… ì´ë ¥ ì‹œê°í™” ê°€ëŠ¥ (CloudWatch)
* ìƒíƒœ ì „ì´ ìƒíƒœ ë° ë¡œê·¸ ì¶”ì  ê°€ëŠ¥

---

## âœ… ì„ íƒì§€ 2: Spring Scheduler + ìƒíƒœ í…Œì´ë¸”

ë³´ë‹¤ ë‹¨ìˆœí•œ ê²½ìš°ì—ëŠ” **Spring Boot ë‚´ë¶€ì—ì„œ ìƒíƒœ ê¸°ë°˜ Polling + Retry** ë°©ì‹ë„ ì“¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### êµ¬ì¡° ì˜ˆì‹œ:

1. `unload_result` í…Œì´ë¸”ì— ìƒíƒœê°’ ê¸°ë¡ (PENDING â†’ DONE/FAILED)
2. UNLOAD ì‹¤íŒ¨ ì‹œ `status=FAILED`ë¡œ ê¸°ë¡ í›„ retry ëŒ€ìƒ ì„ ì •
3. S3ì— íŒŒì¼ ì¡´ì¬í•˜ëŠ”ì§€ ì£¼ê¸°ì ìœ¼ë¡œ í™•ì¸ (`AmazonS3Client.doesObjectExist`)
4. ì¡°ê±´ ë§Œì¡± ì‹œ Kafka event ë°œí–‰

### Scheduler ì˜ˆì‹œ:

```java
@Scheduled(fixedDelay = 60000)
public void checkUnloadFiles() {
    List<UnloadResult> pending = repository.findByStatus(Status.PENDING);
    for (UnloadResult result : pending) {
        String key = "unload-results/" + result.getRequestId() + "/output.gz";
        if (s3Client.doesObjectExist(bucketName, key)) {
            result.setStatus(Status.DONE);
            result.setS3FileUrl(generateUrl(key));
            repository.save(result);
            kafkaTemplate.send("unload-complete", result.getRequestId());
        }
    }
}
```

---

## âœ… ì„ íƒì§€ 3: Lambda + Kafka Event â†’ ê²°ê³¼ Polling

* S3 â†’ Lambda â†’ Kafka â†’ Spring Bootë¡œ ìƒíƒœ ê°±ì‹ 
* í”„ë¡ íŠ¸ì—”ë“œëŠ” `GET /api/unload/{id}`ë¡œ polling (ì§ì ‘ ìƒíƒœ í™•ì¸)

ì´ ë°©ì‹ì€ Step Functionsë³´ë‹¤ëŠ” ê°„ë‹¨í•˜ì§€ë§Œ, ì¤‘ê°„ ì´ë²¤íŠ¸ ëˆ„ë½ì— ëŒ€í•œ ë°©ì–´ ë¡œì§ì´ í•„ìš”í•©ë‹ˆë‹¤.

---

## ğŸŸ¨ ë¹„êµ ì •ë¦¬

| ë°©ì‹                           | ì í•© ìƒí™©                | ì¥ì               | ë‹¨ì                   |
| ---------------------------- | -------------------- | --------------- | ------------------- |
| **Step Functions**           | ì „ì²´ ì›Œí¬í”Œë¡œìš° í†µì œ, ì•ˆì •ì„± í•„ìš”  | ì‹œê°í™”, ì¬ì‹œë„, ìƒíƒœ ì¶”ì  | ë³µì¡ë„ ì¦ê°€, ë¹„ìš© ë°œìƒ       |
| **Spring Scheduler Polling** | ê°„ë‹¨í•œ êµ¬ì¡°, UNLOAD ìƒíƒœ ì¶”ì  | êµ¬í˜„ ì‰¬ì›€, ë¹„ìš© ì—†ìŒ    | polling ì£¼ê¸°/ì„±ëŠ¥ ì¡°ì ˆ í•„ìš” |
| **Lambda + Kafka only**      | ì´ë²¤íŠ¸ ê¸°ë°˜, ë¹ ë¥¸ ì‘ë‹µ ì›í•  ë•Œ   | ì´ë²¤íŠ¸ ê¸°ë°˜ ì•Œë¦¼       | ëˆ„ë½ë˜ë©´ polling ë³‘í–‰ í•„ìš”  |

---

## âœ… ê²°ë¡  (ì¶”ì²œ ì¡°í•©)

* **ë‹¨ê¸° MVP**:

  * `Spring Boot + JDBC UNLOAD + ìƒíƒœ í…Œì´ë¸” + Kafka + polling`
  * ê°„ë‹¨í•˜ê³  ìœ ì§€ê´€ë¦¬ ì‰¬ì›€

* **ì¥ê¸° ìš´ì˜ ë˜ëŠ” ì•ˆì •ì„± ê°•í™” í•„ìš” ì‹œ**:

  * `Step Functions + Lambda + Kafka` ì¡°í•©ìœ¼ë¡œ ì „í™˜
  * ìƒíƒœ/ì‹¤íŒ¨ ì¶”ì  ë° ë¦¬ì»¤ë²„ë¦¬ ê°€ëŠ¥

---

í•„ìš”í•˜ì‹œë©´ Step Function `.asl.json` í…œí”Œë¦¿ì´ë‚˜ Spring Scheduler ìƒ˜í”Œ ì „ì²´ ì½”ë“œë„ ë§Œë“¤ì–´ë“œë¦´ ìˆ˜ ìˆì–´ìš”.
ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ê°ˆì§€ ê²°ì •í•˜ì…¨ë‹¤ë©´ ì•Œë ¤ì£¼ì„¸ìš”!


-----
ì¢‹ìŠµë‹ˆë‹¤! Spring Bootì—ì„œ **Redshiftì— UNLOAD ëª…ë ¹ì„ ì‹¤í–‰í•˜ê³ , S3 íŒŒì¼ ë§í¬ë¥¼ ìƒì„±í•˜ì—¬ DBì— ì €ì¥í•˜ëŠ” ì „ì²´ íë¦„**ì„ êµ¬í˜„í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

---

## âœ… ëª©í‘œ

1. UNLOAD ì¿¼ë¦¬ë¥¼ JDBCë¡œ Redshiftì— ì‹¤í–‰
2. S3 ê²½ë¡œë¡œ íŒŒì¼ì´ ì €ì¥ë¨
3. S3 íŒŒì¼ URLì„ ìƒì„±í•´ì„œ DBì— ì €ì¥
4. ì¶”í›„ ì‚¬ìš©ìì—ê²Œ ë‹¤ìš´ë¡œë“œ ë§í¬ ì œê³µ ê°€ëŠ¥

---

## âœ… ì „ì²´ êµ¬ì¡°

* **API**: `/api/unload`
* **ì…ë ¥**: SQL ì¿¼ë¦¬, ìš”ì²­ ID
* **ì¶œë ¥**: ìš”ì²­ IDë¡œ DBì— ì €ì¥ëœ ë§í¬
* **êµ¬ì„± í´ë˜ìŠ¤**:

  * `UnloadRequest` DTO
  * `UnloadResult` Entity
  * `UnloadService`
  * `UnloadController`

---

## âœ… 1. DTO â€“ `UnloadRequest`

```java
public class UnloadRequest {
    private String requestId;
    private String sql;
}
```

---

## âœ… 2. Entity â€“ `UnloadResult`

```java
@Entity
public class UnloadResult {
    @Id
    private String requestId;

    private String s3FileUrl;

    @Enumerated(EnumType.STRING)
    private Status status;

    public enum Status {
        PENDING, DONE, FAILED
    }
}
```

---

## âœ… 3. Repository â€“ `UnloadResultRepository`

```java
public interface UnloadResultRepository extends JpaRepository<UnloadResult, String> {
}
```

---

## âœ… 4. Service â€“ `UnloadService`

```java
@Service
@RequiredArgsConstructor
public class UnloadService {

    private final JdbcTemplate jdbcTemplate;
    private final UnloadResultRepository repository;

    @Value("${s3.bucket}")
    private String s3Bucket;

    @Value("${s3.accessKey}")
    private String accessKey;

    @Value("${s3.secretKey}")
    private String secretKey;

    public void unloadToS3(UnloadRequest request) {
        String s3KeyPrefix = String.format("unload-results/%s/output", request.getRequestId());
        String s3Path = String.format("s3://%s/%s", s3Bucket, s3KeyPrefix);

        String unloadQuery = String.format(
            "UNLOAD ('%s') TO '%s' " +
            "CREDENTIALS 'aws_access_key_id=%s;aws_secret_access_key=%s' " +
            "DELIMITER ',' ADDQUOTES GZIP ALLOWOVERWRITE PARALLEL OFF;",
            request.getSql(), s3Path, accessKey, secretKey
        );

        UnloadResult result = new UnloadResult();
        result.setRequestId(request.getRequestId());
        result.setStatus(UnloadResult.Status.PENDING);
        repository.save(result);

        try {
            jdbcTemplate.execute(unloadQuery);

            String s3FileUrl = String.format("https://%s.s3.amazonaws.com/%s.gz", s3Bucket, s3KeyPrefix);

            result.setStatus(UnloadResult.Status.DONE);
            result.setS3FileUrl(s3FileUrl);
            repository.save(result);

        } catch (Exception e) {
            result.setStatus(UnloadResult.Status.FAILED);
            repository.save(result);
            throw new RuntimeException("UNLOAD failed", e);
        }
    }

    public Optional<UnloadResult> getResult(String requestId) {
        return repository.findById(requestId);
    }
}
```

---

## âœ… 5. Controller â€“ `UnloadController`

```java
@RestController
@RequiredArgsConstructor
@RequestMapping("/api/unload")
public class UnloadController {

    private final UnloadService unloadService;

    @PostMapping
    public ResponseEntity<?> unload(@RequestBody UnloadRequest request) {
        unloadService.unloadToS3(request);
        return ResponseEntity.ok("UNLOAD started for: " + request.getRequestId());
    }

    @GetMapping("/{requestId}")
    public ResponseEntity<?> getResult(@PathVariable String requestId) {
        return unloadService.getResult(requestId)
            .map(ResponseEntity::ok)
            .orElse(ResponseEntity.notFound().build());
    }
}
```

---

## âœ… 6. application.yml ì˜ˆì‹œ

```yaml
s3:
  bucket: your-bucket-name
  accessKey: YOUR_AWS_ACCESS_KEY
  secretKey: YOUR_AWS_SECRET_KEY
```

---

## âœ… ì˜ˆì‹œ ì‚¬ìš© íë¦„

### ğŸ”¹ POST `/api/unload`

```json
{
  "requestId": "abc123",
  "sql": "SELECT * FROM large_table"
}
```

### ğŸ”¹ GET `/api/unload/abc123`

```json
{
  "requestId": "abc123",
  "s3FileUrl": "https://your-bucket-name.s3.amazonaws.com/unload-results/abc123/output.gz",
  "status": "DONE"
}
```

---

## âœ… í™•ì¥: Kafka ì—°ë™ ë˜ëŠ” Polling

* í˜„ì¬ëŠ” `UNLOAD â†’ JDBC ì™„ë£Œ â†’ ì¦‰ì‹œ ì €ì¥` ë°©ì‹ì…ë‹ˆë‹¤.
* ì¶”í›„ S3 Lambda ì´ë²¤íŠ¸ ìˆ˜ì‹ ì„ í†µí•œ Kafka â†’ `status=DONE` ì—…ë°ì´íŠ¸ ë¡œì§ë„ ì¶”ê°€ ê°€ëŠ¥

---

## âœ… ë³´ì•ˆ íŒ

* JDBC UNLOAD ì‹œ `aws_iam_role='arn:aws:iam::xxx:role/RedshiftUnloadRole'` ë°©ì‹ ì‚¬ìš© ì¶”ì²œ (accessKey, secretKey ëŒ€ì‹ )
* S3 ë²„í‚·ì— PreSigned URLì„ ë°œê¸‰í•´ì„œ ë‹¤ìš´ë¡œë“œ ì œí•œ ê°€ëŠ¥

---

í•„ìš” ì‹œ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì´ì–´ì„œ ë“œë¦´ ìˆ˜ ìˆì–´ìš”:

* Kafka ì—°ë™
* S3 PreSigned URLë¡œ ë³´ì•ˆ ì„¤ì •
* Step Functions/Lambda ì—°ê³„ë¡œ ë¹„ë™ê¸° ì²˜ë¦¬

ì›í•˜ì‹œëŠ” íë¦„ì´ ë” ìˆìœ¼ë©´ ë§ì”€ ì£¼ì„¸ìš”.

--------------

ë‹¹ì‹ ì´ ì›í•˜ì‹œëŠ” ê¸°ëŠ¥ì€ ë‹¤ìŒê³¼ ê°™ì€ **Redshift â†’ UNLOAD â†’ S3 â†’ ì•Œë¦¼ ìˆ˜ì‹  â†’ íŒŒì¼ ë§í¬ ë‹¤ìš´ë¡œë“œ ì œê³µ** íë¦„ì…ë‹ˆë‹¤. ê° ë‹¨ê³„ë¥¼ ì•„ë˜ì²˜ëŸ¼ êµ¬ì„±í•˜ë©´ ë©ë‹ˆë‹¤:

---

### âœ… ì „ì²´ ì•„í‚¤í…ì²˜ ìš”ì•½

```
[Sprint Boot API] â”€â”¬â”€> [Redshift UNLOAD Query ì‹¤í–‰ (JDBC)]
                  â”‚
                  â””â”€> [UNLOAD ëŒ€ìƒ ì¿¼ë¦¬ ìƒì„± + S3 ëŒ€ìƒ ì§€ì •]
                       â†“
       Redshift â†’ UNLOAD â†’ S3 (1-week retention policy)
                       â†“
              [S3 ObjectCreated Lambda Trigger]
                       â†“
          [Kafka Producer â†’ Kafka Event ë°œí–‰]
                       â†“
            [Spring Boot Listener â†’ í´ë¼ì´ì–¸íŠ¸ ì „ì†¡]
```

---

### âœ… êµ¬ì„± ìš”ì†Œë³„ ìƒì„¸ ê°€ì´ë“œ

---

#### 1. **Spring Boot APIì—ì„œ UNLOAD ìš”ì²­ ë°›ê¸°**

* ì‚¬ìš©ìë¡œë¶€í„° ì¿¼ë¦¬, ID ë“±ì„ ë°›ì•„ APIë¡œ ìš”ì²­
* ìš”ì²­ ì˜ˆì‹œ:

```json
POST /api/unload
{
  "query": "SELECT * FROM your_large_table",
  "requestId": "12345"
}
```

---

#### 2. **Redshift UNLOAD ì‹¤í–‰ (JDBC ì‚¬ìš©)**

```java
public void unloadToS3(String query, String s3Path, String accessKey, String secretKey) {
    String unloadQuery = String.format(
        "UNLOAD ('%s') TO '%s' " +
        "CREDENTIALS 'aws_access_key_id=%s;aws_secret_access_key=%s' " +
        "DELIMITER ',' ADDQUOTES GZIP ALLOWOVERWRITE PARALLEL OFF;",
        query, s3Path, accessKey, secretKey
    );

    jdbcTemplate.execute(unloadQuery);
}
```

* `s3Path`: ì˜ˆì‹œ `"s3://your-bucket/unload-results/12345/output"`
* `PARALLEL OFF`: í•˜ë‚˜ì˜ gzip íŒŒì¼ë¡œ ë°›ê¸° ìœ„í•¨
* **ì£¼ì˜**: UNLOAD ëª…ë ¹ì€ Redshiftì—ì„œ ì§ì ‘ ì‹¤í–‰ë˜ë©° S3 ê¶Œí•œì´ í•„ìš”

---

#### 3. **S3ì— ì—…ë¡œë“œ ì™„ë£Œë˜ë©´ Lambda Trigger**

* S3 bucketì— `ObjectCreated` ì´ë²¤íŠ¸ ì„¤ì •
* í•´ë‹¹ prefix (`unload-results/`) ì•„ë˜ íŒŒì¼ì´ ìƒê¸°ë©´ Lambda ì‹¤í–‰
* Lambda ì˜ˆì‹œ ì½”ë“œ (Python):

```python
import json, boto3
from kafka import KafkaProducer

producer = KafkaProducer(bootstrap_servers='your-kafka:9092')

def lambda_handler(event, context):
    for record in event['Records']:
        s3_info = record['s3']
        bucket = s3_info['bucket']['name']
        key = s3_info['object']['key']
        
        file_url = f"https://{bucket}.s3.amazonaws.com/{key}"
        request_id = key.split('/')[1]

        payload = {
            "requestId": request_id,
            "s3FileUrl": file_url
        }

        producer.send("unload-complete-topic", json.dumps(payload).encode('utf-8'))
```

---

#### 4. **Spring Bootì—ì„œ Kafka Consumer ë“±ë¡**

```java
@KafkaListener(topics = "unload-complete-topic", groupId = "unload-group")
public void handleUnloadComplete(String message) {
    ObjectMapper mapper = new ObjectMapper();
    Map<String, String> data = mapper.readValue(message, new TypeReference<>() {});
    
    String requestId = data.get("requestId");
    String fileUrl = data.get("s3FileUrl");

    // DBì— ì €ì¥í•˜ê±°ë‚˜ í´ë¼ì´ì–¸íŠ¸ì— ì „ì†¡ ë“± í›„ì²˜ë¦¬
}
```

---

#### 5. **S3 íŒŒì¼ ë§í¬ ì‚¬ìš©ìì—ê²Œ ì œê³µ**

* Kafka Event ìˆ˜ì‹  í›„ DBë‚˜ ìºì‹œ(Redis ë“±)ì— ì €ì¥
* ì‚¬ìš©ì ìš”ì²­ ì‹œ í•´ë‹¹ IDë¡œ íŒŒì¼ ë§í¬ ì¡°íšŒ

---

#### 6. **S3 Retention (1ì£¼ì¼ ì„¤ì •)**

* S3 ì½˜ì†” > Lifecycle Policy ì„¤ì •:

```json
{
  "ID": "TemporaryFiles",
  "Filter": {
    "Prefix": "unload-results/"
  },
  "Expiration": {
    "Days": 7
  },
  "Status": "Enabled"
}
```

---

### ğŸ”„ ì§„í–‰ìƒí™© Polling

* Springì—ì„œ UNLOAD ì‹œì‘ í›„ ìƒíƒœë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´ DBì— ìƒíƒœ ì €ì¥ (`PENDING`, `DONE`, `FAILED`)
* Kafka ìˆ˜ì‹  ì‹œ ìƒíƒœ `DONE`ìœ¼ë¡œ ë³€ê²½
* ì‚¬ìš©ì: `/api/unload/status/{requestId}`ë¡œ polling

---

### âœ… ë³´ì•ˆ ê¶Œí•œ ì„¤ì •

* S3ì— UNLOADí•˜ë ¤ë©´ Redshift IAM Role ë˜ëŠ” Access Key í•„ìš”
* ìµœì†Œ ê¶Œí•œ ì •ì±…:

```json
{
  "Effect": "Allow",
  "Action": [
    "s3:PutObject",
    "s3:GetObject",
    "s3:ListBucket"
  ],
  "Resource": [
    "arn:aws:s3:::your-bucket-name/unload-results/*",
    "arn:aws:s3:::your-bucket-name"
  ]
}
```

---

### âœ… ìš”ì•½ API ìŠ¤í™

| API                           | ì„¤ëª…                |
| ----------------------------- | ----------------- |
| `POST /api/unload`            | UNLOAD ì‹œì‘ ìš”ì²­      |
| `GET /api/unload/status/{id}` | í˜„ì¬ ì§„í–‰ ìƒíƒœ ì¡°íšŒ       |
| `GET /api/unload/file/{id}`   | ì™„ë£Œëœ S3 ë‹¤ìš´ë¡œë“œ ë§í¬ ì œê³µ |

---

í•„ìš”í•˜ì‹œë©´ ì•„ë˜ ì „ì²´ ì˜ˆì œë“¤ë„ êµ¬ì„±í•´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

* Lambda ì „ì²´ ì½”ë“œ
* Kafka ì„¤ì • YAML
* Spring Boot KafkaListener êµ¬ì„±
* Redshift UNLOAD ì¿¼ë¦¬ builder

ì›í•˜ì‹œëŠ” êµ¬ì„± ë°©í–¥ ìˆìœ¼ì‹œë©´ ì•Œë ¤ì£¼ì„¸ìš”.

